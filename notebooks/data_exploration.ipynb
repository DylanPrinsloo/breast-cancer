{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import cv2\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Conv2DTranspose, concatenate\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.metrics import f1_score, roc_auc_score, roc_curve, classification_report, accuracy_score\n",
    "\n",
    "def load_json(json_path):\n",
    "    with open(json_path, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    return data\n",
    "\n",
    "def parse_json(data):\n",
    "    categories = {cat['id']: cat['name'] for cat in data['categories']}\n",
    "    images = {img['id']: img['file_name'] for img in data['images']}\n",
    "    return categories, images\n",
    "\n",
    "def load_image_and_mask(image_path, mask_path):\n",
    "    image = cv2.imread(image_path)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n",
    "    return image, mask\n",
    "\n",
    "def plot_images_with_masks(images, masks, categories, category_names):\n",
    "    fig, axes = plt.subplots(nrows=2, ncols=4, figsize=(10, 10))\n",
    "    for i, (image_path, mask_path, category) in enumerate(zip(images, masks, categories)):\n",
    "        image, mask = load_image_and_mask(image_path, mask_path)\n",
    "        row, col = divmod(i, 4)\n",
    "        ax_image = axes[0, col]\n",
    "        ax_image.imshow(image)\n",
    "        ax_image.axis('off')\n",
    "        ax_image.set_title(f\"Categoria: {category_names[category]}\")\n",
    "        ax_mask = axes[1, col]\n",
    "        ax_mask.imshow(image)\n",
    "        ax_mask.imshow(mask, cmap='jet', alpha=0.55)\n",
    "        ax_mask.axis('off')\n",
    "    plt.subplots_adjust(wspace=0, hspace=0)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def load_annotations(json_path):\n",
    "    with open(json_path, 'r') as f:\n",
    "        annotations = json.load(f)\n",
    "    return annotations\n",
    "\n",
    "def load_image_and_mask_pil(image_path, mask_path, target_size=(256, 256)):\n",
    "    image = Image.open(image_path).convert('RGB')\n",
    "    mask = Image.open(mask_path).convert('L')\n",
    "    image = image.resize(target_size, Image.Resampling.LANCZOS)\n",
    "    mask = mask.resize(target_size, Image.Resampling.LANCZOS)\n",
    "    image = np.array(image)\n",
    "    mask = np.array(mask)\n",
    "    return image, mask\n",
    "\n",
    "def visualize_batch(images, masks):\n",
    "    batch_size = len(images)\n",
    "    fig, axes = plt.subplots(batch_size, 2, figsize=(10, batch_size * 5))\n",
    "    for i in range(batch_size):\n",
    "        ax_image = axes[i, 0]\n",
    "        ax_image.imshow(images[i])\n",
    "        ax_image.axis('off')\n",
    "        ax_mask = axes[i, 1]\n",
    "        ax_mask.imshow(masks[i], cmap='gray')\n",
    "        ax_mask.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def dataset_generator(image_dir, mask_dir, annotations, batch_size, target_size=(256, 256)):\n",
    "    image_info = annotations['images']\n",
    "    while True:\n",
    "        np.random.shuffle(image_info)\n",
    "        for batch_start in range(0, len(image_info), batch_size):\n",
    "            images = []\n",
    "            masks = []\n",
    "            for i in range(batch_start, min(batch_start + batch_size, len(image_info))):\n",
    "                image_data = image_info[i]\n",
    "                image_filename = image_data['file_name']\n",
    "                image_path = os.path.join(image_dir, image_filename)\n",
    "                mask_filename = f\"{image_filename}_mask.png\"\n",
    "                mask_path = os.path.join(mask_dir, mask_filename)\n",
    "                try:\n",
    "                    image, mask = load_image_and_mask_pil(image_path, mask_path, target_size)\n",
    "                except (FileNotFoundError, ValueError) as e:\n",
    "                    print(f\"Error loading image or mask: {e}\")\n",
    "                    continue\n",
    "                images.append(image / 255.0)\n",
    "                masks.append(mask / 255.0)\n",
    "            yield np.array(images), np.array(masks)\n",
    "\n",
    "def unet_vgg16_model(input_shape):\n",
    "    vgg_base = VGG16(weights='imagenet', include_top=False, input_shape=input_shape)\n",
    "    for layer in vgg_base.layers:\n",
    "        layer.trainable = False\n",
    "\n",
    "    inputs = vgg_base.input\n",
    "    c1 = vgg_base.get_layer('block1_conv2').output\n",
    "    p1 = MaxPooling2D((2, 2))(c1)\n",
    "    c2 = vgg_base.get_layer('block2_conv2').output\n",
    "    p2 = MaxPooling2D((2, 2))(c2)\n",
    "    c3 = vgg_base.get_layer('block3_conv3').output\n",
    "    c4 = vgg_base.get_layer('block4_conv3').output\n",
    "\n",
    "    u5 = Conv2DTranspose(256, (2, 2), strides=(2, 2), padding='same')(c4)\n",
    "    u5 = concatenate([u5, c3])\n",
    "    c5 = Conv2D(256, (3, 3), activation='relu', padding='same')(u5)\n",
    "    c5 = Conv2D(256, (3, 3), activation='relu', padding='same')(c5)\n",
    "\n",
    "    u6 = Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(c5)\n",
    "    u6 = concatenate([u6, c2])\n",
    "    c6 = Conv2D(128, (3, 3), activation='relu', padding='same')(u6)\n",
    "    c6 = Conv2D(128, (3, 3), activation='relu', padding='same')(c6)\n",
    "\n",
    "    u7 = Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(c6)\n",
    "    u7 = concatenate([u7, c1])\n",
    "    c7 = Conv2D(64, (3, 3), activation='relu', padding='same')(u7)\n",
    "    c7 = Conv2D(64, (3, 3), activation='relu', padding='same')(c7)\n",
    "\n",
    "    outputs = Conv2D(1, (1, 1), activation='sigmoid')(c7)\n",
    "    model = Model(inputs=[inputs], outputs=[outputs])\n",
    "    return model\n",
    "\n",
    "def plot_training_metrics(history):\n",
    "    plt.figure(figsize=(14, 5))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "    plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "    plt.title('Accuracy during Training and Validation')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(history.history['loss'], label='Training Loss')\n",
    "    plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "    plt.title('Loss during Training and Validation')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "def evaluate_model(model, data_gen, steps):\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    for i in range(steps):\n",
    "        x_batch, y_batch = next(data_gen)\n",
    "        predictions = model.predict(x_batch)\n",
    "        predictions_bin = (predictions >= 0.5).astype(np.int32)\n",
    "        y_true.extend(y_batch.flatten())\n",
    "        y_pred.extend(predictions_bin.flatten())\n",
    "        if i % 20 == 0:\n",
    "            plot_single_prediction(x_batch, y_batch, predictions_bin)\n",
    "    y_true = np.array(y_true)\n",
    "    y_pred = np.array(y_pred)\n",
    "    if np.array_equal(np.unique(y_true), [0, 1]) and np.array_equal(np.unique(y_pred), [0, 1]):\n",
    "        f1 = f1_score(y_true, y_pred)\n",
    "        auc = roc_auc_score(y_true, y_pred)\n",
    "        print(f'F1-Score: {f1}')\n",
    "        print(f'AUC: {auc}')\n",
    "        fpr, tpr, _ = roc_curve(y_true, y_pred)\n",
    "        plt.figure()\n",
    "        plt.plot(fpr, tpr, marker='.')\n",
    "        plt.title('ROC Curve')\n",
    "        plt.xlabel('False Positive Rate')\n",
    "        plt.ylabel('True Positive Rate')\n",
    "        plt.show()\n",
    "        print(classification_report(y_true, y_pred))\n",
    "    else:\n",
    "        print(\"Error: y_true or y_pred is not in the expected binary format.\")\n",
    "\n",
    "def plot_single_prediction(images, masks_true, masks_pred):\n",
    "    image = images[0]\n",
    "    mask_true = masks_true[0]\n",
    "    mask_pred = masks_pred[0]\n",
    "    mask_true_bin = (mask_true >= 0.5).astype(np.int32)\n",
    "    accuracy = accuracy_score(mask_true_bin.flatten(), mask_pred.flatten())\n",
    "    fig, ax = plt.subplots(1, 3, figsize=(15, 5))\n",
    "    ax[0].imshow(image)\n",
    "    ax[0].set_title('Original Image')\n",
    "    ax[0].axis('off')\n",
    "    ax[1].imshow(mask_true.squeeze(), cmap='gray')\n",
    "    ax[1].set_title('Original Mask')\n",
    "    ax[1].axis('off')\n",
    "    ax[2].imshow(image)\n",
    "    ax[2].imshow(mask_pred.squeeze(), cmap='jet', alpha=0.5)\n",
    "    ax[2].set_title(f'Predicted Mask (Accuracy: {accuracy:.2f})')\n",
    "    ax[2].axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Define paths and parameters for training and validation datasets, model\n",
    "input_shape = (256, 256, 3)\n",
    "batch_size = 8\n",
    "train_image_dir = '/kaggle/input/dental-x-ray-computacional-vision-segmentation/Dental X_Ray/train'\n",
    "train_mask_dir = '/kaggle/input/dental-x-ray-computacional-vision-segmentation/Dental X_Ray/train/train_mask'\n",
    "train_annotation_file = '/kaggle/input/dental-x-ray-computacional-vision-segmentation/train_annotations.coco.json'\n",
    "valid_image_dir = '/kaggle/input/dental-x-ray-computacional-vision-segmentation/Dental X_Ray/valid'\n",
    "valid_mask_dir = '/kaggle/input/dental-x-ray-computacional-vision-segmentation/Dental X_Ray/valid/valid_mask'\n",
    "valid_annotation_file = '/kaggle/input/dental-x-ray-computacional-vision-segmentation/valid_annotations.coco.json'\n",
    "train_annotations = load_annotations(train_annotation_file)\n",
    "valid_annotations = load_annotations(valid_annotation_file)\n",
    "train_data_gen = dataset_generator(train_image_dir, train_mask_dir, train_annotations, batch_size, target_size=(256, 256))\n",
    "valid_data_gen = dataset_generator(valid_image_dir, valid_mask_dir, valid_annotations, batch_size, target_size=(256, 256))\n",
    "train_steps_per_epoch = len(train_annotations['images']) // batch_size\n",
    "valid_steps_per_epoch = len(valid_annotations['images']) // batch_size\n",
    "model = unet_vgg16_model(input_shape)\n",
    "model.compile(optimizer=Adam(), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "history = model.fit(\n",
    "    train_data_gen,\n",
    "    steps_per_epoch=train_steps_per_epoch,\n",
    "    validation_data=valid_data_gen,\n",
    "    validation_steps=valid_steps_per_epoch,\n",
    "    epochs=7,\n",
    "    verbose=1\n",
    ")\n",
    "plot_training_metrics(history)\n",
    "model.save('vgg16_unet_model.h5')\n",
    "test_image_dir = '/kaggle/input/dental-x-ray-computacional-vision-segmentation/Dental X_Ray/test'\n",
    "test_mask_dir = '/kaggle/input/dental-x-ray-computacional-vision-segmentation/Dental X_Ray/test/test_mask'\n",
    "test_annotation_file = '/kaggle/input/dental-x-ray-computacional-vision-segmentation/test_annotations.coco.json'\n",
    "test_annotations = load_annotations(test_annotation_file)\n",
    "test_data_gen = dataset_generator(test_image_dir, test_mask_dir, test_annotations, batch_size, target_size=(256, 256))\n",
    "test_steps = len(test_annotations['images']) // batch_size\n",
    "evaluate_model(model, test_data_gen, test_steps)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
